{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scenario A - Supplier Data Cleaning\n",
        "Step 1: Understanding the Data - we can tell there's no direct key to merge on, so we'll unify both data sets instead."
      ],
      "metadata": {
        "id": "6bnrao-tirvK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LMRzJ3Qh7Wy",
        "outputId": "e9d743b8-dcd0-4700-a19a-42c7aca32a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Quality/Choice  Grade               Finish  Thickness (mm)  Width (mm)  \\\n",
            "0            3rd  C200S  gebeizt und geglüht            2.77        1100   \n",
            "1            3rd  C300S            ungebeizt            2.65        1075   \n",
            "2            3rd  C100S  gebeizt und geglüht            2.20        1100   \n",
            "3            2nd  C100S              gebeizt            2.86        1100   \n",
            "4            1st  C300S            ungebeizt            2.88        1050   \n",
            "\n",
            "                          Description  Gross weight (kg)   RP02      RM  \\\n",
            "0                Längs- oder Querisse              13983  333.6   606.2   \n",
            "1                Längs- oder Querisse              13047  717.7     0.0   \n",
            "2       Kantenfehler - FS-Kantenrisse              14155  368.9     0.0   \n",
            "3                Längs- oder Querisse              11381  368.9   601.7   \n",
            "4  Sollmasse (Gewicht) unterschritten              10072    0.0  1213.0   \n",
            "\n",
            "   Quantity     AG      AI  \n",
            "0      0.00  16.11  0.0054  \n",
            "1      0.00  16.11  0.0046  \n",
            "2     10.84   0.00  0.0061  \n",
            "3     22.87   0.00  0.0062  \n",
            "4     22.87   0.00  0.0041  \n",
            "       Material          Description  Article ID  Weight (kg)  Quantity  \\\n",
            "0           HDC    Material is Oiled    23048203        24469        52   \n",
            "1        S235JR    Material is Oiled    23040547        16984        41   \n",
            "2        S235JR  Material is Painted    23046057         9162        28   \n",
            "3  DX51D +AZ150    Material is Oiled    23041966        12119        66   \n",
            "4           HDC  Material is Painted    23043884        17260        26   \n",
            "\n",
            "       Reserved  \n",
            "0  NOT RESERVED  \n",
            "1  NOT RESERVED  \n",
            "2  NOT RESERVED  \n",
            "3       VANILLA  \n",
            "4  NOT RESERVED  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the files\n",
        "df1 = pd.read_excel(\"supplier_data1.xlsx\")\n",
        "df2 = pd.read_excel(\"supplier_data2.xlsx\")\n",
        "\n",
        "# Quick look at the first rows in each dataset\n",
        "print(df1.head())\n",
        "print(df2.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Cleaning and Unifiying both Datasets"
      ],
      "metadata": {
        "id": "tbvO5KSPkIkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip whitespace in all string columns\n",
        "for col in df1.select_dtypes(include=\"object\").columns:\n",
        "    df1[col] = df1[col].str.strip()\n",
        "\n",
        "for col in df2.select_dtypes(include=\"object\").columns:\n",
        "    df2[col] = df2[col].str.strip()\n",
        "\n",
        "#Create a unified dataset structure\n",
        "df1_clean = pd.DataFrame({\n",
        "    \"Grade/Material\": df1[\"Grade\"],\n",
        "    \"Finish\": df1[\"Finish\"],\n",
        "    \"Thickness (mm)\": df1[\"Thickness (mm)\"],\n",
        "    \"Width (mm)\": df1[\"Width (mm)\"],\n",
        "    \"Description\": df1[\"Description\"],\n",
        "    \"Weight (kg)\": df1[\"Gross weight (kg)\"],\n",
        "    \"Quantity\": df1[\"Quantity\"],\n",
        "    \"Quality/Choice\": df1[\"Quality/Choice\"],\n",
        "    \"Reserved\": None,  # Not available in df1\n",
        "    \"Article ID\": None,  # Not available in df1\n",
        "    \"RP02\": df1[\"RP02\"],\n",
        "    \"RM\": df1[\"RM\"],\n",
        "    \"AG\": df1[\"AG\"],\n",
        "    \"AI\": df1[\"AI\"],\n",
        "    \"Source\": \"supplier_data1\"\n",
        "})\n",
        "\n",
        "df2_clean = pd.DataFrame({\n",
        "    \"Grade/Material\": df2[\"Material\"],\n",
        "    \"Finish\": None,  # TODO: check - maybe extract finish from the desc\n",
        "    \"Thickness (mm)\": None,\n",
        "    \"Width (mm)\": None,\n",
        "    \"Description\": df2[\"Description\"],\n",
        "    \"Weight (kg)\": df2[\"Weight (kg)\"],\n",
        "    \"Quantity\": df2[\"Quantity\"],\n",
        "    \"Quality/Choice\": None,\n",
        "    \"Reserved\": df2[\"Reserved\"],\n",
        "    \"Article ID\": df2[\"Article ID\"],\n",
        "    \"RP02\": None,  # Not available in df2\n",
        "    \"RM\": None,  # Not available in df2\n",
        "    \"AG\": None,  # Not available in df2\n",
        "    \"AI\": None,  # Not available in df2\n",
        "    \"Source\": \"supplier_data2\"\n",
        "})\n"
      ],
      "metadata": {
        "id": "YFKVrVy1jmP1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Concatenating and Exporting"
      ],
      "metadata": {
        "id": "PzlGOrG3kizI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine into one dataset\n",
        "inventory_dataset = pd.concat([df1_clean, df2_clean], ignore_index=True)\n",
        "\n",
        "# Handle missing values (filling missing values with 'Unknown')\n",
        "inventory_dataset = inventory_dataset.fillna(\"Unknown\")\n",
        "\n",
        "# Export\n",
        "inventory_dataset.to_csv(\"inventory_dataset.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AIBCv4AksV_",
        "outputId": "e0db32c2-9c73-4acd-dc28-774e71ff8f83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3398404562.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  inventory_dataset = pd.concat([df1_clean, df2_clean], ignore_index=True)\n"
          ]
        }
      ]
    }
  ]
}